{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24fc2910-b205-4101-aba2-06dae04e9e0f",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc29b85-6be2-42ca-bf08-66a2655ee3f0",
   "metadata": {},
   "source": [
    "we can get rid of features by two ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5de40-1ba9-4f8c-ac63-c99e530b8d61",
   "metadata": {},
   "source": [
    "1. feature elimination\n",
    "2. feature extraction\n",
    "\n",
    "Feature elimination is what it sounds like: we reduce the feature space by eliminating features. In the GDP example above, instead of considering every single variable, we might drop all variables except the three we think will best predict what the U.S.’s gross domestic product will look like. Advantages of feature elimination methods include simplicity and maintaining interpretability of your variables.\n",
    "\n",
    "As a disadvantage, though, you gain no information from those variables you’ve dropped. If we only use last year’s GDP, the proportion of the population in manufacturing jobs per the most recent American Community Survey numbers, and unemployment rate to predict this year’s GDP, we’re missing out on whatever the dropped variables could contribute to our model. By eliminating features, we’ve also entirely eliminated any benefits those dropped variables would bring.\n",
    "\n",
    "Feature extraction, however, doesn’t run into this problem. Say we have ten independent variables. In feature extraction, we create ten “new” independent variables, where each “new” independent variable is a combination of each of the ten “old” independent variables. However, we create these new independent variables in a specific way and order these new variables by how well they predict our dependent variable.\n",
    "\n",
    "You might say, “Where does the dimensionality reduction come into play?” Well, we keep as many of the new independent variables as we want, but we drop the “least important ones.” Because we ordered the new variables by how well they predict our dependent variable, we know which variable is the most important and least important. But — and here’s the kicker — because these new independent variables are combinations of our old ones, we’re still keeping the most valuable parts of our old variables, even when we drop one or more of these “new” variables!\n",
    "\n",
    "Principal component analysis is a technique for feature extraction — so it combines our input variables in a specific way, then we can drop the “least important” variables while still retaining the most valuable parts of all of the variables! As an added benefit, each of the “new” variables after PCA are all independent of one another. This is a benefit because the assumptions of a linear model require our independent variables to be independent of one another. If we decide to fit a linear regression model with these “new” variables (see “principal component regression” below), this assumption will necessarily be satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dba91f-2031-4181-8313-fed6abae3596",
   "metadata": {},
   "source": [
    "When should I use PCA?\n",
    "Do you want to reduce the number of variables, but aren’t able to identify variables to completely remove from consideration?\n",
    "Do you want to ensure your variables are independent of one another?\n",
    "Are you comfortable making your independent variables less interpretable?\n",
    "If you answered “yes” to all three questions, then PCA is a good method to use. If you answered “no” to question 3, you should not use PCA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6374f-5048-407a-ae20-17869241ace2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
